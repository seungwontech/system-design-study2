# Chapter 1: 근접성 서비스 (Proximity Service) 발표 자료

> **발표자**: 길현준  

---

## 목차

1. [1단계: 문제 이해 및 설계 범위 확정](#1-1단계-문제-이해-및-설계-범위-확정)
2. [2단계: 개략적 설계](#2-2단계-개략적-설계)
3. [3단계: 상세 설계](#3-3단계-상세-설계)
4. [면접 질문 Q&A](#4-면접-질문-qa)
5. [토론 주제](#5-토론-주제)
6. [참고 자료](#6-참고-자료)

---

## 1. 1단계: 문제 이해 및 설계 범위 확정

### 근접성 서비스란?

**정의**: 현재 위치에서 가까운 시설(음식점, 호텔, 주유소 등)을 찾는 서비스

**실제 사례**:
- Yelp: 주변 맛집 검색
- Google Maps: 가까운 k개 주유소
- 배달의민족, 카카오맵: 주변 음식점

### 기능 요구사항

| 요구사항 | 세부 내용 |
|----------|----------|
| 주변 사업장 검색 | 위치(위도/경도) + 반경 기반 검색 |
| 사업장 CRUD | 소유주가 정보 추가/수정/삭제 |
| 상세 정보 조회 | 고객이 사업장 상세 정보 확인 |

### 비기능 요구사항

- **낮은 지연(Low Latency)**: 신속한 검색 응답
- **데이터 보호**: GDPR, CCPA 준수 (위치 정보 민감)
- **고가용성 & 확장성**: 피크 시간 트래픽 대응

### QPS 계산 (Back-of-envelope)

```
DAU = 1억 명
사업장 수 = 2억 개
일일 검색 = 5회/사용자
QPS = (1억 × 5) / 10^5 = 5,000 QPS
```

---

## 2. 2단계: 개략적 설계

### API 설계

**검색 API**
```
GET /v1/search/nearby
Parameters:
  - latitude (decimal): 위도
  - longitude (decimal): 경도  
  - radius (int, optional): 반경 (기본값 5000m)
```

**사업장 CRUD API**
| Method | Endpoint | 설명 |
|--------|----------|------|
| GET | /v1/businesses/:id | 상세 정보 조회 |
| POST | /v1/businesses | 신규 등록 |
| PUT | /v1/businesses/:id | 정보 수정 |
| DELETE | /v1/businesses/:id | 삭제 |

### 개략적 아키텍처

```
[Client] → [Load Balancer]
                ↓
    ┌───────────┴───────────┐
    ↓                       ↓
[LBS]                 [Business Service]
(위치 기반 서비스)         (사업장 서비스)
    ↓                       ↓
[Read Replicas]     ←    [Primary DB]
```

| 컴포넌트 | 역할 | 특징 |
|----------|------|------|
| **로드밸런서** | URL 경로 기반 라우팅 | /search/nearby → LBS |
| **LBS** | 주변 사업장 검색 | 읽기 전용, 무상태, QPS 높음 |
| **사업장 서비스** | CRUD 처리 | 쓰기 위주, QPS 낮음 |
| **DB 클러스터** | Primary-Replica 구조 | 쓰기는 Primary, 읽기는 Replica |

### 주변 사업장 검색 알고리즘 (핵심!)

**핵심 메시지**: "2차원 데이터를 1차원으로 변환하여 색인"

```
지리 정보 색인
├── 해시 기반 (Hash)
│   ├── 균등 격자 (Even Grid)
│   ├── 지오해시 (Geohash) ★
│   └── 카르테시안 계층
└── 트리 기반 (Tree)
    ├── 쿼드트리 (Quadtree) ★
    ├── 구글 S2
    └── R-트리
```

#### 방안 1: 2차원 검색 (비효율적)

```sql
SELECT business_id FROM business
WHERE latitude BETWEEN {lat-r} AND {lat+r}
  AND longitude BETWEEN {lon-r} AND {lon+r}
```

**문제점**: 
- 테이블 전체 스캔 필요
- 위도/경도 각각에 인덱스를 만들어도 교집합 연산 비용 큼

#### 방안 2: 균등 격자

- 전 세계를 동일 크기 격자로 분할
- **문제점**: 
  - 데이터 분포 불균등 (뉴욕 vs 사막)
  - 인접 격자 찾기 어려움

#### 방안 3: 지오해시 (Geohash) ★

**핵심 개념**: 2차원 좌표 → 1차원 문자열 변환

**인코딩 과정**:
1. 전 세계를 4분면으로 분할
   - 위도: [-90, 0] → 0, [0, 90] → 1
   - 경도: [-180, 0] → 0, [0, 180] → 1
2. 원하는 정밀도까지 재귀적 분할
3. Base32 인코딩 (예: `9q9hvu`)

**지오해시 길이와 격자 크기**:

| 길이 | 격자 크기 | 용도 |
|------|----------|------|
| 4 | 39.1km × 19.5km | 넓은 범위 |
| 5 | 4.9km × 4.9km | 중간 범위 |
| 6 | 1.2km × 609m | 근거리 |

**검색 반경 → 지오해시 길이 매핑**:

| 반경 | 지오해시 길이 |
|------|-------------|
| 0.5km | 6 |
| 1-2km | 5 |
| 5-20km | 4 |

**경계 조건 이슈 (Edge Cases)** - 면접 빈출!

1. **이슈 1: 공통 접두어 없음**
   - 예: `u000` vs `ezzz` (30km 거리인데 접두어 다름)
   - 적도/자오선 경계에서 발생

2. **이슈 2: 다른 격자에 위치**
   - 아주 가까워도 경계선으로 격자가 다를 수 있음

**해결책**: 현재 격자 + 인접 8개 격자 모두 검색

#### 방안 4: 쿼드트리 (Quadtree) ★

**핵심 개념**: 인구 밀도에 따라 동적 격자 크기 조절

**특징**:
- 메모리 기반 자료구조 (DB 아님!)
- 각 LBS 서버에서 시작 시 구축
- 격자당 사업장 수 ≤ 100개 될 때까지 분할

**구축 알고리즘**:
```java
public void buildQuadtree(TreeNode node) {
  if (countBusinesses(node) > 100) {
    node.subdivide();
    for (TreeNode child : node.getChildren()) {
      buildQuadtree(child);
    }
  }
}
```

**메모리 계산**:
- 말단 노드: 832 bytes (좌표 32B + 사업장 ID 100개 × 8B)
- 내부 노드: 64 bytes (좌표 32B + 포인터 4개 × 8B)
- **총 메모리: ~1.71GB** (서버 1대에 충분!)

**운영 고려사항**:
- 서버 시작 시 트리 구축 → 시작 시간 증가
- 배포 시 동시에 많은 서버 재시작 금지 (청/녹 배포 주의)

#### 지오해시 vs 쿼드트리 비교 (면접 필수!)

| 항목 | 지오해시 | 쿼드트리 |
|------|---------|---------|
| **구현 난이도** | 쉬움 | 어려움 (트리 구축) |
| **격자 크기** | 고정 | 동적 (밀도 기반) |
| **인덱스 갱신** | 쉬움 (O(1)) | 어려움 (O(log n)) |
| **k-nearest** | 추가 로직 필요 | 자연스럽게 지원 |
| **멀티스레드** | 문제 없음 | 락 필요 |

**기술 사용 현황**:

| 기술 | 사용 기업 |
|------|----------|
| 지오해시 | Bing Maps, Redis, MongoDB, Lyft |
| 쿼드트리 | Yext |
| 지오해시 + 쿼드트리 | Elasticsearch |
| S2 | Google Maps, Tinder |

---

## 3. 3단계: 상세 설계

### 데이터베이스 규모 확장

**Business 테이블**: business_id 기준 샤딩

**지오해시 테이블**: 
- 데이터 크기 작음 (~1.71GB) → 샤딩 불필요
- **Read Replica 증설로 부하 분산** 권장

**테이블 설계 방안**:
```
방안 1: [geohash, JSON_array_of_business_ids] → 갱신 어려움, 락 필요
방안 2: [geohash, business_id] 복합 키 → 추천!
```

### 캐시 전략

**캐시 필요성 검토** (면접 포인트!)
- 읽기 중심 + 데이터 작음 → 캐시 효과 불확실
- Read Replica로도 충분할 수 있음
- **벤치마킹 후 결정** 필요

**캐시 키 설계**:
- ❌ 위도/경도 직접 사용 → 위치 미세 변화로 캐시 미스
- ✅ **지오해시 사용** → 같은 격자 내 동일 키

**캐시 데이터**:
| 키 | 값 | 저장소 |
|----|----|----|
| 지오해시 | 사업장 ID 목록 | Redis (지오해시) |
| 사업장 ID | 사업장 상세 정보 | Redis (사업장 정보) |

### 최종 아키텍처

```
[Client] → [Load Balancer]
               ↓
    ┌──────────┴──────────┐
    ↓                     ↓
  [LBS]            [Business Service]
    ↓                     ↓
    └────→ [Redis Cluster] ←────┘
           ├── 지오해시
           └── 사업장 정보
                  ↓ 동기화
           [DB Cluster]
           ├── Primary
           └── Replicas
```

**주변 검색 플로우**:
1. 클라이언트 → LBS: 위치 + 반경
2. LBS: 지오해시 길이 계산 (예: 500m → 길이 6)
3. LBS: 현재 + 인접 8개 지오해시 계산
4. LBS → Redis: 각 지오해시의 사업장 ID 조회 (병렬)
5. LBS → Redis: 사업장 상세 정보 조회
6. 거리 계산, 정렬 후 반환

---

## 4. 면접 질문 Q&A

### Q1. 지오해시와 쿼드트리 중 어떤 것을 선택하겠는가?

**Answer**:
> 상황에 따라 다릅니다.
> 
> **지오해시 선택**:
> - 구현 단순성이 중요할 때
> - 인덱스 갱신이 빈번할 때
> - Redis나 기존 DB의 지오해시 지원 활용 시
>
> **쿼드트리 선택**:
> - k-nearest 검색이 핵심일 때 (주유소 찾기)
> - 데이터 밀도 편차가 클 때
> - 메모리에 충분히 올릴 수 있을 때
>
> 실제로 **Elasticsearch는 둘 다 사용**합니다.

### Q2. 지오해시의 경계 조건 문제를 어떻게 해결하는가?

**Answer**:
> 두 가지 경계 이슈가 있습니다:
> 
> 1. **공통 접두어 없음**: 가까운데 지오해시가 완전히 다름
>    - 해결: 현재 격자 + **인접 8개 격자** 모두 검색
> 
> 2. **격자 경계선 이슈**: 바로 옆인데 다른 격자
>    - 해결: 마찬가지로 인접 격자 포함 검색
>
> 인접 지오해시 계산은 **O(1)** 상수 시간에 가능합니다.

### Q3. QPS 5000을 어떻게 처리하겠는가?

**Answer**:
> 1. **LBS 무상태 설계**: 수평 확장으로 서버 추가
> 2. **Read Replica**: DB 읽기 부하 분산
> 3. **Redis 캐시**: 지오해시별 결과 캐싱 (TTL 1일)
> 4. **다중 리전**: 지역별 사용자 트래픽 분산
> 5. **CDN**: 정적 컨텐츠 캐싱
>
> 피크 시간(점심, 저녁)에는 **오토스케일링**으로 대응합니다.

### Q4. 쿼드트리 메모리 계산을 해보라

**Answer**:
> ```
> 사업장 수: 200M
> 격자당 최대: 100개
> 
> 말단 노드 수 = 200M / 100 = 2M
> 내부 노드 수 = 2M × 1/3 = 0.67M
> 
> 말단 메모리 = 2M × 832B = 1.66GB
> 내부 메모리 = 0.67M × 64B = 0.04GB
> 
> 총 메모리 ≈ 1.71GB
> ```
> 
> 서버 1대 메모리에 충분히 수용 가능합니다.

### Q5. 캐시가 정말 필요한가?

**Answer**:
> 바로 "캐시 추가"를 결론 내리기보다 **분석이 필요**합니다:
>
> **캐시 불필요 가능성**:
> - 전체 데이터가 ~2GB로 작음
> - 이미 메모리에서 처리 가능
> - Read Replica로 읽기 분산 가능
>
> **캐시 필요 조건**:
> - 벤치마크 결과 지연 시간 목표 미달
> - Read Replica 추가보다 비용 효율적
> - 지역별 캐시로 글로벌 지연 감소 필요
>
> **결론**: 벤치마킹 후 결정, 무조건 캐시가 답은 아님

### Q6. 실시간 사업장 정보 갱신이 필요하다면?

**Answer**:
> 현재 설계는 "다음날 반영" 요구사항 기반입니다.
>
> **실시간 필요 시 변경점**:
> 1. **쿼드트리**: 락 기반 동시성 제어 필요 → 복잡도 증가
> 2. **지오해시**: 캐시 무효화 전략 필요
>    - Write-through 또는 이벤트 기반 invalidation
> 3. **메시지 큐**: 변경 이벤트 비동기 처리
> 4. **CDC(Change Data Capture)**: DB 변경 실시간 감지

### Q7. 사업장이 1조 개라면 어떻게 확장하겠는가?

**Answer**:
> **지오해시 테이블 샤딩**:
> - 지오해시 접두어 기반 샤딩
> - 지역별 샤드 분리
>
> **쿼드트리 분산**:
> - 지역별 별도 쿼드트리
> - 서비스 메시로 라우팅
>
> **Tiered Storage**:
> - Hot data: 인기 지역 → 메모리/SSD
> - Cold data: 비인기 지역 → HDD/S3
>
> **핵심**: 지역 기반 파티셔닝 + 데이터 지역성 활용

---

## 5. 토론 주제

### 토론 1: 지오해시 vs 쿼드트리, 우리 서비스에는?

**질문**: 여러분이 배달 앱(배달의민족 등)을 설계한다면 어떤 방식을 선택하겠는가?

**토론 포인트**:
- 배달 반경은 보통 고정 (1-5km)
- 음식점 밀도는 지역마다 다름
- 실시간 음식점 상태 변경 필요 (영업 중/마감)
- Redis 지오해시 지원 활용 가능

### 토론 2: 캐시 전략 - 언제 무효화할 것인가?

**질문**: 사업장 정보가 변경되었을 때 캐시를 어떻게 관리하겠는가?

**토론 포인트**:
- TTL 기반 vs 이벤트 기반
- 일관성 vs 성능 트레이드오프
- Cache-aside vs Write-through
- 야간 일괄 갱신의 장단점

### 토론 3: 개인정보 보호와 위치 서비스

**질문**: GDPR/CCPA 준수를 위해 위치 데이터를 어떻게 처리해야 하는가?

**토론 포인트**:
- 위치 데이터 저장 최소화
- 익명화/가명화 처리
- 사용자 동의 및 삭제 요청 처리
- 지역별 데이터 격리 (Data Residency)

---

## 6. 참고 자료

### 공식 문서
- [Redis GEOHASH Commands](https://redis.io/commands/geohash)
- [PostGIS Documentation](https://postgis.net/)
- [Google S2 Geometry](https://s2geometry.io/)
- [Uber H3](https://h3geo.org/)

### 기술 블로그
- [Lyft: 10M QPS Redis Architecture](https://www.youtube.com/watch?v=cSFWlF96Sds)
- [Tinder: Geosharded Recommendations](https://medium.com/tinder/geosharded-recommendations-part-1-sharding-approach-d5d54e0ec77a)

### 도구
- [Geohash Explorer](https://www.movable-type.co.uk/scripts/geohash.html)
- [S2 Cell Viewer](https://s2.inair.space)
- [Hilbert Curve Visualization](http://bit-player.org/extras/hilbert/hilbert-mapping.html)

### 실무 사례

| 기업 | 기술 | 특징 |
|------|------|------|
| **Lyft** | Redis Geohash | 10M QPS 처리, 실시간 드라이버 매칭 |
| **Uber** | H3 (육각형 격자) | 자체 개발, 왜곡 최소화 |
| **Tinder** | Google S2 | 지역 기반 샤딩 |
| **Elasticsearch** | Geohash + Quadtree | 하이브리드 접근 |

---

## 1장 요약 마인드맵

```
근접성 서비스
├── 1단계: 요구사항
│   ├── 기능: 검색, CRUD, 조회
│   ├── 비기능: 지연, 보호, 확장성
│   └── QPS: 5,000
├── 2단계: 개략적 설계
│   ├── API: /search/nearby, /businesses
│   ├── 아키텍처: LBS + Business Service
│   └── 알고리즘
│       ├── 지오해시 ★
│       ├── 쿼드트리 ★
│       └── 구글 S2
├── 3단계: 상세 설계
│   ├── DB 확장: 샤딩 + Replica
│   ├── 캐시: Redis (지오해시 키)
│   └── 다중 리전 배포
└── 4단계: 마무리
```

---

*Last Updated: 2025-01-17*
