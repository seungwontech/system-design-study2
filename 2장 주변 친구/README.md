# 0️⃣ 한 줄 요약

> 주변 친구 서비스의 본질은 새로운 친구를 찾는 문제가 아니라, 이미 정해진 친구들의 위치를 효율적으로 갱신하고 조회하는 문제다.
> 

---

# 1️⃣ 문제 정의: ‘주변 친구’란 무엇인가

### 1. 사용자 관점 정의

주변 친구 서비스는 다음 두 요소의 결합이다.

- **주변 (Near)**
    - 사용자의 현재 좌표 (latitude, longitude)
    - 검색 반경 (ex: 500m, 1km, 5km)
- **친구 (Friend)**
    - 단순히 “모든 사용자” ❌
    - **이미 관계가 정의된 사용자 집합** ⭕

### 2. 친구 관계의 현실적인 케이스

책의 시나리오를 현실 서비스 관점으로 풀면, 친구는 대략 이런 도메인으로 나뉜다.

- 나를 **팔로우한 사람**
- 내가 **팔로잉한 사람**
- 팔로우 ↔ 팔로잉이 모두 성립한 사람
- 친구 요청을 **수락한 사람**
- 전화번호 / 주소록을 **공유한 사람**

👉 핵심 포인트

> 친구 집합은 “동적으로 변하지만, 위치에 비해 훨씬 느리게 변한다.”
> 

---

# 2️⃣ 핵심 통찰: 이 문제의 진짜 난이도는 어디에 있는가

많은 사람이 이 문제를 이렇게 오해한다.

> ❌ “주변에 누가 있는지 빨리 찾는 문제다”
> 

하지만 책이 말하는 진짜 본질은 이거다.

> ✅ “이미 정해진 친구들의 위치를 지속적으로 갱신하고, 빠르게 조회하는 문제다”
> 

### 왜 친구가 핵심이 아닌가?

- 친구 추가/삭제는 **이벤트 빈도가 낮음**
- 대부분의 시간 동안 친구 목록은 **고정**

### 왜 위치가 핵심인가?

- 사용자는 **움직인다**
- 위치는 분 단위, 초 단위로 갱신된다
- 사용자 수가 늘수록 위치 업데이트 트래픽이 폭증한다

👉 그래서 문제는

**Friend Discovery ❌ → Location Update & Query ⭕**

---

# 3️⃣ 도메인 분해: 필요한 핵심 도메인들

이 챕터를 잘 풀려면, 도메인을 명확히 나누는 게 중요해.

### 1️⃣ User Domain

- user_id
- 기본 프로필 정보

### 2️⃣ Friend Relationship Domain

- follower / following
- friend_request
- contact_based_friend

👉 특징

- 변경 빈도 낮음
- 정합성 중요 (강한 일관성)

### 3️⃣ Location Domain (🔥 핵심)

- user_id
- latitude / longitude
- timestamp
- geo index (geohash / quad-tree / s2 등)

👉 특징

- 변경 빈도 매우 높음
- 최신성 중요
- 약한 일관성 허용 가능

### 4️⃣ Query Domain

- 기준 사용자
- 검색 반경
- 필터링 대상 친구 집합

---

# 4️⃣ 서비스 흐름을 한 문장으로 요약하면

> “내 친구 목록을 기준으로, 그들의 최신 위치 중에서 나와 일정 거리 안에 있는 사람만 빠르게 골라낸다.”
> 

이 문장이 곧:

- 책의 시나리오
- 시스템 설계의 목표
- 블로그 글의 중심축

---

# 5️⃣ 왜 책에서 지리 인덱싱을 강조하는가 (역사적 배경)

이 문제가 어려워진 이유는 단순하다.

- 스마트폰 보급 → 실시간 위치 수집 가능
- SNS 확산 → 친구 수 폭증
- 실시간 서비스 요구 → DB 단순 조회로는 한계

그래서:

- **RDB 단순 where lat/lng 조건 ❌**
- **지리 인덱스 기반 탐색 ⭕**

책에서 geohash, quad-tree, S2 같은 구조를 꺼내는 이유는

👉 *“친구 수가 아니라 위치 데이터 규모가 병목이 되기 때문”*이야.

---

# 6️⃣ 친구 위치 갱신은 어떻게 전달되는가

## 📌 Pub/Sub와 Socket의 역할 분리

앞에서 정리했듯,

주변 친구 서비스의 핵심은 **친구 목록이 아니라 위치 변화**다.

그렇다면 다음 질문은 자연스럽다.

> “친구의 위치가 바뀌었을 때,
> 
> 
> 이 변화는 어떻게 나에게 전달되는가?”
> 

이 질문에 답하기 위해서는

**이벤트 전파**와 **클라이언트 전달**을 분리해서 생각해야 한다.

## 1. 친구 위치 변화는 ‘이벤트’다

친구의 위치 변화는 다음과 같은 상황에서 발생한다.

- 앱 실행(접속)
- 위치 좌표 변경
- 앱 종료(이탈)

이 모든 것은 공통적으로 하나의 성격을 가진다.

> “상태 변화 이벤트”
> 

중요한 점은

**내가 친구의 위치를 주기적으로 물어보는 게 아니라**,

**친구 스스로가 변화가 생겼을 때 이벤트를 발생시킨다는 것**이다.

## 2. 서버 내부에서 필요한 것: Pub/Sub

대규모 서비스에서는 서버가 보통 여러 대로 구성된다.

- A 서버: 친구의 위치 업데이트를 처리
- B 서버: 나의 WebSocket 연결을 담당
- C 서버: 또 다른 사용자의 세션을 담당

이때 문제가 생긴다.

> “A 서버에서 발생한 친구 위치 이벤트를
> 
> 
> B 서버는 어떻게 알 수 있을까?”
> 

여기서 등장하는 개념이 **Pub/Sub**이다.

### Pub/Sub의 역할

- 특정 이벤트를 **publish**
- 관심 있는 서버들이 이를 **subscribe**
- 서버 간 이벤트를 느슨하게 연결

즉,

> Pub/Sub는 서버 내부에서 ‘누가 관심 있는지 모르는 상태로’
이벤트를 전달하기 위한 구조다.
> 

중요한 포인트는 이것이다.

- Pub/Sub는 **서버 ↔ 서버 통신**
- 클라이언트와는 직접 연결되지 않는다

## 3. “그럼 구독하고 있으면 바로 내 화면에 오나?”

여기서 흔한 오해가 하나 있다.

> “내가 친구 토픽을 구독하고 있으면
> 
> 
> 친구 위치 변경이 바로 내 정보로 오는 거 아닌가?”
> 

**서버 기준으로는 맞다.**

하지만 **클라이언트 기준으로는 틀리다.**

왜냐하면 Pub/Sub가 전달하는 대상은

**내 앱이 아니라 ‘서버 프로세스’**이기 때문이다.

즉, 이 시점까지의 흐름은 이렇다.

```
친구 위치 변경
→ 이벤트 발행
→ Pub/Sub를 통해 서버가 이벤트 수신
```

여기까지는 **서버 내부 상태**일 뿐,

사용자 화면에는 아직 아무 변화도 없다.

## 4. 그래서 Socket이 필요하다

서버가 이벤트를 알게 되었다고 해서

클라이언트가 자동으로 알게 되지는 않는다.

클라이언트는 기본적으로 **수동적인 존재**다.

- 서버가 보내주지 않으면 모른다
- 주기적으로 물어보면 폴링 비용이 커진다

그래서 필요한 것이 바로 **Socket(WebSocket 등)** 이다.

### Socket의 역할

- 서버 ↔ 클라이언트 간 **지속 연결**
- 서버가 **능동적으로(push)** 데이터 전송 가능
- 위치 변화처럼 즉각적인 반영이 필요한 UI에 적합

즉,

> Pub/Sub는 “서버들 사이의 이벤트 분배”를 담당하고,
Socket은 “그 결과를 사용자 화면에 전달”하는 역할을 맡는다.
> 

## 📌 전체 흐름을 정리하면

주변 친구 서비스의 위치 갱신 흐름은 다음과 같다.

```
1. 친구가 이동 → 위치 변경 발생
2. 친구 앱 → 서버로 위치 업데이트 전송
3. 서버가 최신 위치 저장
4. 서버가 "친구 위치 변경" 이벤트 publish (Pub/Sub)
5. 내 세션을 담당하는 서버가 이벤트 subscribe
6. 서버가 WebSocket을 통해 내 앱에 push
7. 내 화면에서 친구 위치 갱신
```

여기서 핵심은 역할 분리다.

| 구분 | 담당 |
| --- | --- |
| 이벤트 발생 | 사용자(친구) |
| 이벤트 전파 | Pub/Sub |
| 화면 반영 | Socket |

# 💡 왜 이 분리가 중요한가

이 구조를 쓰는 이유는 단순히 “실시간이어서”가 아니다.

- 서버 수평 확장이 쉬워진다
- 친구 수가 늘어나도 구조가 무너지지 않는다
- 클라이언트는 복잡한 로직 없이 UI에 집중할 수 있다

즉,

> Pub/Sub + Socket 구조는
‘실시간성’과 ‘확장성’을 동시에 만족시키기 위한 설계 선택이다.
> 

## 5. Redis Pub/Sub의 대안으로서 Erlang / Elixir

앞에서 살펴본 구조에서

Socket(WebSocket 등)은 사실상 대체가 불가능한 기술이다.

- 서버가 클라이언트에게 **능동적으로(push)** 데이터를 전달해야 하고
- 실시간 위치 변화가 UI에 즉시 반영되어야 하기 때문이다

반면, **Redis Pub/Sub**는 상황에 따라 대체 가능하다.

책에서는 이 대안으로 **Erlang / Elixir 기반 접근**을 제시한다.

---

# 7️⃣ 왜 이 구조에서 해시 링이 잘 맞는가

*(해시 링의 동작 원리는 1권에서 이미 다뤘다고 가정한다)*

앞선 글에서 살펴본 주변 친구 서비스는 다음과 같은 특성을 가진다.

- 친구 수는 많아질 수 있다
- 친구별 위치 정보는 매우 자주 갱신된다
- Redis는 단일 서버로 감당하기 어렵다
- 따라서 Redis는 **여러 대로 분산**되어야 한다

이 시점에서 중요한 질문은 더 이상

“해시 링이 무엇인가?”가 아니다.

> “이 문제에 왜 해시 링이 잘 맞는가?”
> 

## 1. 이 문제는 ‘균등 분배’가 가장 중요한 문제다

주변 친구 서비스에서 Redis가 처리하는 데이터는 대부분 다음과 같다.

- 친구별 최신 위치
- 친구별 상태(접속/이탈)
- 이벤트 처리에 필요한 임시 상태

이 데이터들의 공통점은 명확하다.

- **친구(user) 단위로 완전히 독립적**
- 읽기/쓰기 빈도가 높음
- 특정 친구가 다른 친구의 데이터에 의존하지 않음

즉,

> Redis 분산의 목적은 복잡한 트랜잭션이 아니라
부하를 고르게 나누는 것이다.
> 

해시 링은 바로 이 요구에 가장 잘 맞는다.

## 2. 친구 수가 늘어날수록 “쏠림 방지”가 핵심이 된다

친구 수가 적을 때는 Redis 한 대로도 버틸 수 있다.

하지만 친구 수가 늘어날수록 문제는 달라진다.

- 일부 Redis에 친구가 몰리면
- 그 Redis만 CPU / 메모리 / 네트워크가 먼저 한계에 도달한다
- 전체 서비스의 체감 성능이 떨어진다

이 구조에서 중요한 것은:

> “모든 Redis가 비슷한 양의 친구를 책임지도록 만드는 것”
> 

해시 링은:

- 친구(user_id)를 기준으로
- Redis 노드에 **확률적으로 균등하게 분산**시킨다

그래서 친구 수가 늘어날수록 오히려 효과가 커진다.

## 3. Redis 노드 장애를 ‘국지적 문제’로 만들 수 있다

이 시스템에서 Redis는 보통:

- 캐시
- 최신 상태 저장소
- 이벤트 처리를 돕는 보조 저장소

역할을 맡는다.

이런 경우 Redis 장애는:

- “전체 시스템 중단”이 아니라
- *“일부 친구 상태가 잠시 사라지는 문제”**여야 한다.

해시 링 기반 분산에서는:

- Redis 한 대가 장애가 나더라도
- 그 Redis가 담당하던 **일부 친구만 영향**을 받는다
- 다른 Redis에 있던 친구 데이터는 그대로 유지된다

즉,

> 장애의 반경을 최소 단위(친구 단위)로 제한할 수 있다.
> 

이건 운영 관점에서 매우 큰 장점이다.

## 4. 이후 설계(이벤트 전파)를 자연스럽게 만든다

앞에서 다룬 것처럼, 이 시스템은 결국 다음 구조로 확장된다.

- Redis는 해시 링으로 분산됨
- 친구 이벤트는 서로 다른 Redis에 흩어짐
- 따라서 이벤트 전파 계층이 필요해짐
    - Pub/Sub
    - Streams
    - Erlang / Elixir 기반 분산 메시징

여기서 중요한 점은:

> 해시 링은 “이벤트 전파 문제를 숨기지 않는다”
> 

오히려:

- “데이터는 분산되어 있다”
- “이벤트는 다른 곳에 있다”

라는 사실을 전제로 설계를 강제한다.

그래서:

- Pub/Sub
- 이벤트 스트리밍
- 분산 런타임

같은 설계로 **자연스럽게 이어진다**.

## 5. 이 문제에서 해시 링은 ‘최적화’가 아니라 ‘전제 조건’이다

정리하면, 해시 링은 이 시스템에서:

- 성능 튜닝용 기술 ❌
- 구현 디테일 ❌

이 아니다.

> 해시 링은 “친구 수가 계속 늘어나는 시스템”을
전제로 설계하기 위한 기본 조건이다.
> 
- 친구 단위 분산
- 균등한 부하
- 장애 영향 최소화
- 이벤트 기반 확장 설계

이 모든 조건을 가장 자연스럽게 만족시키는 방식이

바로 해시 링이다.

---

## 한 줄 정리

> 이 구조에서 해시 링이 잘 맞는 이유는
Redis를 빠르게 만들기 위해서가 아니라,
친구 수가 늘어날 때 시스템이 ‘망가지지 않게’ 만들기 때문이다.
> 

# 8️⃣ 책에서 Erlang / Elixir을 해결책으로 언급하는 이유

책의 관점은 단순하다.

> Redis Pub/Sub는 “서버 간 이벤트 전파”를 담당하지만,
> 
> 
> 이 역할은 반드시 외부 브로커가 아니어도 된다.
> 

Erlang / Elixir가 실행되는 **BEAM 런타임**은

애초에 다음 기능을 기본 전제로 설계되었다.

- 경량 프로세스 기반 동시성
- 프로세스 간 메시지 패싱
- **노드 간 분산 메시지 전달**

즉, **서버 여러 대를 하나의 클러스터처럼 묶고**,

그 안에서 이벤트를 직접 주고받는 구조가 가능하다.

## 1. Pub/Sub 관점에서의 역할 비교

### 기존 구조 (Redis Pub/Sub)

```
서버A
  ↓ publish
Redis Pub/Sub
  ↓ subscribe
서버B / 서버 C / 서버 D
```

- 서버 간 이벤트 전달을 Redis가 담당
- 애플리케이션은 메시지 브로커에 의존

### Erlang / Elixir 기반 구조

```
서버A (Elixir Node)
  ↓ message
서버B / 서버 C / 서버 D (Elixir Node)
```

- 서버들이 **직접 메시지를 주고받음**
- Redis 같은 외부 Pub/Sub 레이어 제거 가능

책에서 Erlang / Elixir을 언급하는 이유는 바로 여기 있다.

> “서버 간 이벤트 팬아웃을 런타임이 책임지는 구조”
> 

## 2. Phoenix PubSub가 보여주는 명확한 힌트

Elixir의 대표적인 웹 프레임워크인 **Phoenix**는

이 선택지를 아주 노골적으로 드러낸다.

Phoenix PubSub는 두 가지 방식을 모두 지원한다.

- **Distributed Elixir 기반 PubSub**
    - 서버들이 직접 메시지를 교환
- **Redis 기반 PubSub**
    - Redis를 외부 브로커로 사용

즉, 프레임워크 차원에서 이미 이렇게 말하고 있는 셈이다.

> “Redis를 써도 되고, 안 써도 된다.”
> 

이건 단순한 구현 편의가 아니라,

**아키텍처 선택지 자체가 다르다는 증거**다.

## 3. 그렇다면 Socket은 왜 여전히 필요한가

여기서 중요한 오해를 하나 짚어야 한다.

> Erlang / Elixir을 쓰면 Socket도 필요 없어지는가?
> 

답은 **아니다**.

Erlang / Elixir이 대체하는 것은

**서버 ↔ 서버 간 이벤트 전파 레이어**다.

하지만 사용자 화면에 실시간으로 반영하려면 여전히:

- 서버가
- 클라이언트에게
- 즉시 데이터를 밀어줘야 한다

이 역할은 **WebSocket / Phoenix Channel** 같은

지속 연결 기반 기술이 담당한다.

즉,

- **Pub/Sub** → 대체 가능
- **Socket** → 대체 불가 (실시간 UX 요구 때문)

## 4. Erlang / Elixir 접근의 장단점

### ✅ 장점 (책이 해결책으로 언급하는 이유)

- 외부 메시지 브로커 제거 → 아키텍처 단순화
- 서버 수평 확장 시 이벤트 전파 구조가 자연스럽게 동작
- 실시간 시스템에 최적화된 런타임 모델

### ⚠️ 현실적인 제약

- 분산 노드 운영 책임이 애플리케이션 쪽으로 이동
- Erlang / Elixir 생태계와 팀 숙련도 문제
- Redis처럼 “범용 인프라” 대비 도입 장벽 존재

그래서 이 선택은 기술의 우열 문제가 아니라

**조직과 서비스 성격에 따른 트레이드오프**다.
